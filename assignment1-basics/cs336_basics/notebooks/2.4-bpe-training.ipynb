{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 BPE Tokenizer Training (15 pts)\n",
    "\n",
    "**Problem (train_bpe):** Implement BPE training\n",
    "- Input: `input_path`, `vocab_size`, `special_tokens`\n",
    "- Output: `vocab`, `merges`\n",
    "- Test: `uv run pytest tests/test_train_bpe.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Sketch\n",
    "1. Initialize vocab with 256 byte values\n",
    "2. Pre-tokenize using GPT-2 regex pattern\n",
    "3. Iteratively merge most frequent adjacent pair (ties broken lexicographically)\n",
    "4. No merging across pre-token boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Development and testing here\n",
    "# Clean implementation goes in cs336_basics/tokenizer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Decisions\n",
    "-\n",
    "\n",
    "## Test Results\n",
    "```\n",
    "# paste pytest output here\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
